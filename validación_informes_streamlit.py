# -*- coding: utf-8 -*-
import io
import os
import re
import zipfile
import unicodedata
from datetime import datetime
from collections import defaultdict
from typing import Optional, Tuple, List, Dict
from PIL import Image
import pandas as pd
import streamlit as st
from openpyxl import load_workbook
from openpyxl.styles import PatternFill
from openpyxl.utils import get_column_letter
from pathlib import Path
from contextlib import contextmanager

# ============================
# --------- CONFIG UI --------
# ============================
LOGO_PATH = Path(__file__).parent / "logo.png"
logo_img = Image.open(LOGO_PATH)
st.set_page_config(page_title="Validaciones Maestro VIH", page_icon=logo_img, layout="wide")

col_logo, col_title = st.columns([1, 9])
with col_logo:
    st.image(logo_img, width=100)

st.title("‚úÖ Script de validaci√≥n de indicadores MER (VIHCA)")
st.caption("TX_PVLS / TX_CURR / HTS_TST ‚Ä¢ Reglas de consistencia por Sexo, Poblaci√≥n y Rango de edad")

with st.expander("‚ÑπÔ∏è C√≥mo usar", expanded=False):
    st.markdown(
        """
1) **Carga** uno o varios `.xlsx` o un `.zip` con subcarpetas.  
2) Pulsa **Procesar**.  
3) Usa los **segmentadores** (Pa√≠s / Depto / Sitio).  
4) **Descarga** el Excel (completo o filtrado).  
        """
    )

# ====== ESTILOS Y TARJETAS (cajas) ======
CARD_CSS = """
<style>
.card {
  background: var(--background-color, #0e1117);
  border: 1px solid rgba(128,128,128,0.25);
  border-radius: 16px;
  padding: 18px 18px 12px 18px;
  margin: 14px 0 18px 0;
  box-shadow: 0 6px 18px rgba(0,0,0,0.12);
}
@media (prefers-color-scheme: light) {
  .card {
    background: #ffffff;
    border: 1px solid rgba(0,0,0,0.08);
    box-shadow: 0 8px 20px rgba(0,0,0,0.06);
  }
}
.card-header { display:flex; align-items:center; gap:10px; margin-bottom: 12px; }
.card-title  { font-weight:700; font-size:1.15rem; margin:0; letter-spacing:.2px; }
.card-badge  { font-size:.80rem; background:rgba(127,127,127,.15); border:1px solid rgba(127,127,127,.25);
               padding:2px 8px; border-radius:999px; }
.card .stMetric { text-align:center; }
</style>
"""
st.markdown(CARD_CSS, unsafe_allow_html=True)

@contextmanager
def card(title: str, icon: str = "üì¶", badge: Optional[str] = None):
    st.markdown("<div class='card'>", unsafe_allow_html=True)
    header_html = f"""
    <div class='card-header'>
      <div style="font-size:1.2rem">{icon}</div>
      <div class='card-title'>{title}</div>
      {f"<div class='card-badge'>{badge}</div>" if badge else ""}
    </div>
    """
    st.markdown(header_html, unsafe_allow_html=True)
    try:
        with st.container():
            yield
    finally:
        st.markdown("</div>", unsafe_allow_html=True)

# ====== DOCUMENTACI√ìN (como expander) ======
DOC_MD = r"""
# üìñ Documentaci√≥n de validaciones

## Indicadores y reglas
- **Numerador > Denominador (TX_PVLS):** Por sexo y edad, `Numerador ‚â§ Denominador`.
- **Denominador > TX_CURR (PVLS vs TX_CURR):** Por **sexo + tipo de poblaci√≥n + edad**, `Denominador (PVLS) ‚â§ TX_CURR`.
- **TX_CURR ‚â† Dispensaci√≥n_TARV (TX_CURR):** Comparaci√≥n de dos cuadros por **sexo + edad**.
- **CD4 vac√≠o positivo (HTS_TST):** Si `Resultado = Positivo`, **CD4 Basal** no puede estar vac√≠o.
- **Fecha TARV < Diagn√≥stico (HTS_TST):** **Fecha inicio TARV** no puede ser anterior a la **Fecha del diagn√≥stico**.
- **Formato fecha diagn√≥stico (HTS_TST):** Si la fecha viene con `/`, debe cumplir **dd/mm/yyyy**.
- **ID (expediente) duplicado (HTS_TST):** Detecta duplicados en la columna **Id** o **N√∫mero de expediente**.

## Fuentes de ‚ÄúMes de reporte‚Äù
- **HTS_TST:** desde **Fecha del diagn√≥stico** (por fila) ‚Üí `MMM YYYY`.
- **TX_PVLS / TX_CURR:** prioridad **Fecha de reporte** > **Mes de reporte**; si no existen, se usa el fallback de la UI.

## M√©tricas
- Por indicador se acumulan **checks** y **errors**.
- `% Error = errors / checks` global y por combinaci√≥n **(Pa√≠s, Depto, Sitio, Mes, Indicador)**.

## Exportaci√≥n a Excel
- Hoja **Resumen** con total de errores por indicador.
- Una hoja por **indicador** con las filas detectadas.
- Hojas de **M√©tricas** (globales y por mes).
- En hojas de errores se **resalta en rojo** la columna cr√≠tica.
"""
with st.expander("üìñ Documentaci√≥n (clic para ver)", expanded=False):
    st.markdown(DOC_MD)
    st.download_button(
        "‚¨áÔ∏è Descargar documentaci√≥n (Markdown)",
        DOC_MD.encode("utf-8"),
        file_name="documentacion_validaciones.md",
        mime="text/markdown",
        use_container_width=True,
    )
# ====== FIN DOCUMENTACI√ìN ======

# ============================
# ------ CARGA DE INPUTS -----
# ============================
col_u1, col_u2 = st.columns([3, 2])
with col_u1:
    subida_multiple = st.file_uploader(
        "üìÇ Cargar .xlsx (varios) o 1 .zip con subcarpetas",
        type=["xlsx", "zip"],
        accept_multiple_files=True
    )
with col_u2:
    default_pais = st.text_input("Pa√≠s por defecto", "Desconocido")
    default_mes = st.text_input("Mes por defecto ", "Desconocido")

procesar = st.button("‚ñ∂Ô∏è Procesar", use_container_width=True)

# ============================
# ---- ESTADO (CACHE/STORE) --
# ============================
for key, val in {
    "processed": False,
    "df_num": pd.DataFrame(),
    "df_txpv": pd.DataFrame(),
    "df_cd4": pd.DataFrame(),
    "df_tarv": pd.DataFrame(),
    "df_fdiag": pd.DataFrame(),
    "df_currq": pd.DataFrame(),   # TX_CURR vs Dispensaci√≥n_TARV
    "df_iddup": pd.DataFrame(),   # NUEVO: IDs duplicados en HTS_TST
    "metrics_global": defaultdict(lambda: {"errors": 0, "checks": 0}),
    "metrics_by_pds": defaultdict(lambda: {"errors": 0, "checks": 0}),
    # cat√°logo maestro de ubicaciones
    "dim_locs": set(),  # set de tuplas (Pa√≠s, Departamento, Sitio)
    "dim_df": pd.DataFrame(columns=["Pa√≠s", "Departamento", "Sitio"]),
    # selecci√≥n de filtros
    "sel_pais": "Todos",
    "sel_depto": "Todos",
    "sel_sitio": "Todos",
}.items():
    if key not in st.session_state:
        st.session_state[key] = val

# ============================
# ----- CONSTANTES / HELPERS -
# ============================
IND_NUM_GT_DEN     = "num_gt_den"
IND_DEN_GT_CURR    = "den_gt_curr"
IND_CD4_MISSING    = "cd4_missing"
IND_TARV_LT_DIAG   = "tarv_lt_diag"
IND_DIAG_BAD_FMT   = "diag_bad_format"
IND_CURR_Q1Q2_DIFF = "curr_q1q2_diff"  # TX_CURR ‚â† Dispensaci√≥n_TARV
IND_ID_DUPLICADO   = "id_duplicado"    # NUEVO

DISPLAY_NAMES = {
    IND_NUM_GT_DEN:      "Numerador > Denominador",
    IND_DEN_GT_CURR:     "Denominador > TX_CURR",
    IND_CD4_MISSING:     "CD4 vac√≠o positivo",
    IND_TARV_LT_DIAG:    "Fecha TARV < Diagn√≥stico",
    IND_DIAG_BAD_FMT:    "Formato fecha diagn√≥stico",
    IND_CURR_Q1Q2_DIFF:  "TX_CURR ‚â† Dispensaci√≥n_TARV",
    IND_ID_DUPLICADO:    "ID (expediente) duplicado",
}

MESES = {
    "enero","febrero","marzo","abril","mayo","junio",
    "julio","agosto","septiembre","setiembre","octubre","noviembre","diciembre",
    "ene","feb","mar","abr","may","jun","jul","ago","sep","oct","nov","dic",
    "january","february","march","april","may","june",
    "july","august","september","october","november","december",
}
RUIDO_DIRS = {"", ".", "..", "__MACOSX", ".ds_store", ".git"}
INVALID_SHEET_CHARS = r'[:\\/?*\[\]]'
SPAN_ABBR = ["ENE","FEB","MAR","ABR","MAY","JUN","JUL","AGO","SEP","OCT","NOV","DIC"]

def _pct(e, c): return round((e / c * 100.0), 2) if c else 0.0

def _safe_sheet_name(name: str, used: set) -> str:
    base = unicodedata.normalize("NFKD", name).encode("ascii","ignore").decode("ascii")
    base = re.sub(INVALID_SHEET_CHARS, "-", base).strip() or "Hoja"
    base = base[:31]
    candidate = base; i = 1
    while candidate in used:
        suf = f"_{i}"; candidate = base[:31-len(suf)] + suf; i += 1
    used.add(candidate)
    return candidate

def _norm(s) -> str:
    if s is None: return ""
    s = str(s)
    s = unicodedata.normalize("NFKD", s).encode("ascii","ignore").decode("ascii")
    return re.sub(r"\s+", " ", s.strip().lower())

def _normalize_sexo(x) -> str:
    sx = _norm(x)
    if sx.startswith("masc"): return "Masculino"
    if sx.startswith("fem"):  return "Femenino"
    return str(x).strip()

def buscar_columna_multi(columnas, *patrones) -> Optional[str]:
    cols_norm = [_norm(c) for c in columnas]
    for i, cn in enumerate(cols_norm):
        if all(p in cn for p in patrones):
            return columnas[i]
    return None

def month_label_from_value(v: object) -> str:
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return ""
    try:
        dt = pd.to_datetime(v, dayfirst=True, errors="coerce")
        if pd.notna(dt):
            return f"{SPAN_ABBR[dt.month-1]} {dt.year}"
    except Exception:
        pass
    return str(v).strip()

def inferir_pais_mes(path_rel: str, default_pais: str, default_mes: str):
    ruta = path_rel.replace("\\", "/")
    partes = [p for p in ruta.split("/") if p.strip().lower() not in RUIDO_DIRS]
    if partes and partes[-1].lower().endswith(".xlsx"): partes = partes[:-1]
    pais = partes[-2].strip() if len(partes) >= 2 else default_pais
    pais = pais or default_pais
    mes = None
    for seg in reversed(partes):
        toks = re.split(r"[_\-\s/\.]+", _norm(seg))
        if any(t in MESES for t in toks):
            mes = seg.strip(); break
    if not mes:
        base = os.path.basename(path_rel)
        base = re.sub(r"\.xlsx$", "", base, flags=re.IGNORECASE)
        toks = re.split(r"[_\-\s/\.]+", _norm(base))
        if any(t in MESES for t in toks):
            mes = base
    mes = mes or default_mes
    return pais, mes

def leer_excel_desde_bytes(nombre, data_bytes): return pd.ExcelFile(io.BytesIO(data_bytes))

def encontrar_fila_encabezado(df_raw: pd.DataFrame, needles) -> Optional[int]:
    try:
        mask = df_raw.astype(str).apply(
            lambda r: all(any(needle.lower() in str(x).lower() for x in r.values) for needle in needles), axis=1
        ); idxs = df_raw[mask].index.tolist()
        return idxs[0] if idxs else None
    except Exception:
        return None

def normalizar_tabla_por_encabezado(df_raw: pd.DataFrame, idx_header: int):
    columnas = df_raw.iloc[idx_header].fillna("").astype(str).tolist()
    df_body = df_raw.iloc[idx_header + 1:].copy(); df_body.columns = columnas
    return df_body.reset_index(drop=True), columnas

def numeros_seguro(v): return pd.to_numeric(v, errors="coerce")

def _add_metric(ind_key: str, pais: str, mes_rep: str, depto: str = "", sitio: str = "",
                checks_add: int = 0, errors_add: int = 0):
    if checks_add:
        st.session_state.metrics_global[ind_key]["checks"] += checks_add
        st.session_state.metrics_by_pds[(pais or "", depto or "", sitio or "", mes_rep or "", ind_key)]["checks"] += checks_add
    if errors_add:
        st.session_state.metrics_global[ind_key]["errors"] += errors_add
        st.session_state.metrics_by_pds[(pais or "", depto or "", sitio or "", mes_rep or "", ind_key)]["errors"] += errors_add

def _rename_standard_columns(df: pd.DataFrame) -> pd.DataFrame:
    mapping: Dict[str, str] = {}
    for c in df.columns:
        cn = _norm(c)
        if not cn: continue
        if "sexo" in cn or "genero" in cn or "g√©nero" in cn:
            mapping[c] = "Sexo"
        elif ("tipo" in cn and "pobl" in cn) or "poblacion clave" in cn or "poblaci√≥n clave" in cn:
            mapping[c] = "Tipo de poblaci√≥n"
        elif "pais" in cn:
            mapping[c] = "Pa√≠s"
        elif "departamento" in cn or "depto" in cn or "provincia" in cn:
            mapping[c] = "Departamento"
        elif ("servicio" in cn and "salud" in cn) or "sitio" in cn or "clinica" in cn or "cl√≠nica" in cn:
            mapping[c] = "Sitio"
        elif "mes" in cn and "rep" in cn:
            mapping[c] = "Mes de reporte"
        elif "fecha" in cn and "reporte" in cn:
            mapping[c] = "Fecha de reporte"
    return df.rename(columns=mapping)

def _dedupe_columns(cols: List[str]) -> List[str]:
    seen: Dict[str, int] = {}
    out: List[str] = []
    for c in cols:
        if c in seen:
            seen[c] += 1
            out.append(f"{c}__{seen[c]}")
        else:
            seen[c] = 0
            out.append(c)
    return out

def _coerce_scalar(v):
    if isinstance(v, pd.Series):
        for x in v.tolist():
            if pd.notna(x) and str(x).strip():
                return x
        return ""
    return v

def _first_col(df: pd.DataFrame, *tokens) -> Optional[str]:
    for c in df.columns:
        cn = _norm(c)
        if all(t in cn for t in tokens):
            return c
    return None

def show_df_or_note(df, note="‚Äî Sin filas para mostrar ‚Äî", height=300):
    if df is None or (isinstance(df, pd.DataFrame) and df.empty):
        st.caption(note); return False
    st.dataframe(df, use_container_width=True, height=height); return True

# ---------- Cat√°logo maestro de ubicaciones ----------
def _canon_txt(x: str) -> str:
    return (str(x).strip() if x is not None else "")

def _canon_triplet(pais: str, depto: str, sitio: str) -> tuple:
    p = _canon_txt(pais); d = _canon_txt(depto); s = _canon_txt(sitio)
    return (p, d, s)

def register_dim(pais: str, depto: str, sitio: str):
    st.session_state.dim_locs.add(_canon_triplet(pais, depto, sitio))

# ============================
# ------- VALIDACIONES -------
# ============================
def procesar_tx_pvls_y_curr(
    xl: pd.ExcelFile, pais_inferido: str, mes_inferido: str, nombre_archivo: str,
    errores_numerador, errores_txpvls
):
    if "TX_PVLS" not in xl.sheet_names: return
    pvls_raw = xl.parse("TX_PVLS", header=None)
    idx_header = encontrar_fila_encabezado(pvls_raw, ["Sexo", "Tipo"])
    if idx_header is None: return
    df_data, columnas = normalizar_tabla_por_encabezado(pvls_raw, idx_header)
    df_data = _rename_standard_columns(df_data)

    # Localizar filas de numerador/denominador
    try:
        idx_num = df_data[df_data.iloc[:,0].astype(str).str.contains("Numerador", case=False, na=False)].index[0]
        idx_den = df_data[df_data.iloc[:,0].astype(str).str.contains("Denominador", case=False, na=False)].index[0]
    except IndexError:
        try:
            idx_num = df_data[df_data.get("TX_PVLS Numerador", "").astype(str).str.contains("Numerador", case=False, na=False)].index[0]
            idx_den = df_data[df_data.get("TX_PVLS Numerador", "").astype(str).str.contains("Denominador", case=False, na=False)].index[0]
        except Exception:
            return

    df_num = _rename_standard_columns(df_data.iloc[idx_num + 1:idx_den].copy())
    df_den = _rename_standard_columns(df_data.iloc[idx_den + 1:].copy())

    # Columnas de edad (tolerante)
    columnas_edad = [c for c in df_data.columns
                     if ("a√±o" in c.lower()) or ("ano" in _norm(c)) or ("65" in c) or ("+" in c) or ("m√°s" in c.lower() and "65" in c.lower())]

    # Pa√≠s/Depto/Sitio
    col_pais   = buscar_columna_multi(df_data.columns, "pais")
    col_depto  = buscar_columna_multi(df_data.columns, "departamento") or buscar_columna_multi(df_data.columns, "depto") or buscar_columna_multi(df_data.columns, "provincia")
    col_sitio  = buscar_columna_multi(df_data.columns, "servicio", "salud") or buscar_columna_multi(df_data.columns, "sitio") or buscar_columna_multi(df_data.columns, "clinica")

    # >>> Fecha/Mes de reporte
    col_fecha_rep = buscar_columna_multi(df_data.columns, "fecha", "reporte")
    col_mesrep    = buscar_columna_multi(df_data.columns, "mes", "reporte")
    def _ctx(row):
        p = str(row.get(col_pais)) if col_pais else pais_inferido
        d = str(row.get(col_depto)) if col_depto else ""
        s = str(row.get(col_sitio)) if col_sitio else ""
        raw_mes = row.get(col_fecha_rep) if col_fecha_rep else (row.get(col_mesrep) if col_mesrep else None)
        m = month_label_from_value(raw_mes) or month_label_from_value(mes_inferido)
        return (p if str(p).strip() else pais_inferido,
                d if str(d).strip() else "",
                s if str(s).strip() else "",
                m if str(m).strip() else month_label_from_value(mes_inferido))
    # <<<

    fila_base_num = idx_header + 3 + idx_num + 1

    # Numerador > Denominador
    for i, row_num in df_num.iterrows():
        sexo = str(row_num.get("Sexo", "")).strip()
        pob  = str(row_num.get("Tipo de poblaci√≥n", "")).strip()
        if _normalize_sexo(sexo) not in ["Masculino", "Femenino"]: continue
        row_den = df_den[(df_den["Sexo"].astype(str).str.strip()==sexo) &
                         (df_den["Tipo de poblaci√≥n"].astype(str).str.strip()==pob)]
        if row_den.empty: continue
        row_den = row_den.iloc[0]
        pais_row, depto_row, sitio_row, mes_rep = _ctx(row_num)
        register_dim(pais_row, depto_row, sito_row:=(sitio_row))

        for col in columnas_edad:
            val_num = numeros_seguro(row_num.get(col))
            val_den = numeros_seguro(row_den.get(col))
            if pd.notna(val_num) and pd.notna(val_den):
                _add_metric(IND_NUM_GT_DEN, pais_row, mes_rep, depto_row, sitio_row, checks_add=1)
                if val_num > val_den:
                    _add_metric(IND_NUM_GT_DEN, pais_row, mes_rep, depto_row, sitio_row, errors_add=1)
                    col_idx = df_data.columns.tolist().index(col)
                    errores_numerador.append({
                        "Pa√≠s": pais_row, "Departamento": depto_row, "Sitio": sitio_row, "Mes de reporte": mes_rep,
                        "Archivo": nombre_archivo, "Sexo": sexo, "Tipo de poblaci√≥n": pob, "Rango de edad": col,
                        "Numerador": float(val_num), "Denominador": float(val_den),
                        "Fila Excel": int(fila_base_num + i), "Columna Excel": get_column_letter(col_idx + 1)
                    })

    # Denominador (PVLS) > TX_CURR
    if "TX_CURR" in xl.sheet_names:
        curr_raw = xl.parse("TX_CURR", header=None)
        idx_curr = encontrar_fila_encabezado(curr_raw, ["Sexo", "Tipo"])
        if idx_curr is None: return
        df_curr, _ = normalizar_tabla_por_encabezado(curr_raw, idx_curr)
        df_curr = _rename_standard_columns(df_curr)
        fila_base_excel_den = idx_header + 3 + idx_den + 1

        for i, row_den in df_den.iterrows():
            sexo = str(row_den.get("Sexo", "")).strip()
            pob  = str(row_den.get("Tipo de poblaci√≥n", "")).strip()
            if _normalize_sexo(sexo) not in ["Masculino", "Femenino"]: continue
            row_curr = df_curr[(df_curr["Sexo"].astype(str).str.strip()==sexo) &
                               (df_curr["Tipo de poblaci√≥n"].astype(str).str.strip()==pob)]
            if row_curr.empty: continue
            row_curr = row_curr.iloc[0]

            pais_row, depto_row, sitio_row, mes_rep = _ctx(row_den)
            register_dim(pais_row, depto_row, sitio_row)

            for col in columnas_edad:
                val_den = numeros_seguro(row_den.get(col))
                val_curr = numeros_seguro(row_curr.get(col))
                if pd.notna(val_den) and pd.notna(val_curr):
                    _add_metric(IND_DEN_GT_CURR, pais_row, mes_rep, depto_row, sitio_row, checks_add=1)
                    if val_den > val_curr:
                        _add_metric(IND_DEN_GT_CURR, pais_row, mes_rep, depto_row, sitio_row, errors_add=1)
                        col_idx = df_data.columns.tolist().index(col)
                        errores_txpvls.append({
                            "Pa√≠s": pais_row, "Departamento": depto_row, "Sitio": sitio_row, "Mes de reporte": mes_rep,
                            "Archivo": nombre_archivo, "Sexo": sexo, "Tipo de poblaci√≥n": pob, "Rango de edad": col,
                            "Denominador (PVLS)": float(val_den), "TX_CURR": float(val_curr),
                            "Fila Excel": int(fila_base_excel_den + i), "Columna Excel": get_column_letter(col_idx + 1)
                        })

def procesar_hts_tst(
    xl: pd.ExcelFile, pais_inferido: str, mes_inferido: str, nombre_archivo: str,
    errores_cd4, errores_fecha_tarv, errores_formato_fecha_diag, errores_iddup
):
    if "HTS_TST" not in xl.sheet_names:
        return

    df_raw = xl.parse("HTS_TST", header=None)
    idx_hts = encontrar_fila_encabezado(df_raw, ["Resultado", "CD4"])
    if idx_hts is None:
        return

    df_data, _ = normalizar_tabla_por_encabezado(df_raw, idx_hts)
    df_data.columns = _dedupe_columns(df_data.columns)
    df_data = _rename_standard_columns(df_data)

    col_resultado = _first_col(df_data, "resultado")
    col_cd4       = _first_col(df_data, "cd4")
    col_tarv      = _first_col(df_data, "inicio", "tar")
    col_diag      = _first_col(df_data, "fecha", "diagn")  # mes de reporte
    col_sitio     = _first_col(df_data, "servicio", "salud") or _first_col(df_data, "sitio") or _first_col(df_data, "clinica")
    col_pais      = _first_col(df_data, "pais")
    col_depto     = _first_col(df_data, "departamento") or _first_col(df_data, "depto") or _first_col(df_data, "provincia")

    if not all([col_resultado, col_cd4, col_diag]):
        return

    fila_base_hts = idx_hts + 3
    for i, row in df_data.iterrows():
        resultado  = str(_coerce_scalar(row.get(col_resultado))).strip().lower()
        cd4        = _coerce_scalar(row.get(col_cd4))
        fecha_diag = _coerce_scalar(row.get(col_diag))
        fecha_tarv = _coerce_scalar(row.get(col_tarv)) if col_tarv else None
        sitio      = _coerce_scalar(row.get(col_sitio)) if col_sitio else ""
        pais_row   = _coerce_scalar(row.get(col_pais))  if col_pais else pais_inferido
        depto_row  = _coerce_scalar(row.get(col_depto)) if col_depto else ""

        mes_rep    = month_label_from_value(fecha_diag) or month_label_from_value(mes_inferido)

        pais_row   = str(pais_row).strip() or pais_inferido
        depto_row  = str(depto_row).strip()
        sitio_row  = str(sitio).strip()
        mes_rep    = str(mes_rep).strip() or month_label_from_value(mes_inferido)

        register_dim(pais_row, depto_row, sitio_row)

        # CD4 vac√≠o cuando Resultado = Positivo
        if resultado == "positivo":
            _add_metric(IND_CD4_MISSING, pais_row, mes_rep, depto_row, sitio_row, checks_add=1)
            if pd.isna(cd4) or str(cd4).strip() == "":
                _add_metric(IND_CD4_MISSING, pais_row, mes_rep, depto_row, sitio_row, errors_add=1)
                errores_cd4.append({
                    "Pa√≠s": pais_row, "Departamento": depto_row, "Sitio": sitio_row, "Mes de reporte": mes_rep,
                    "Archivo": nombre_archivo, "Resultado": "Positivo", "CD4 Basal": "",
                    "Fila Excel": int(fila_base_hts + i), "Columna Excel": col_cd4
                })

        # Fecha TARV < Diagn√≥stico
        if pd.notna(fecha_diag) and pd.notna(fecha_tarv) and str(fecha_tarv).strip():
            try:
                fd = pd.to_datetime(fecha_diag, dayfirst=True, errors="coerce")
                ft = pd.to_datetime(fecha_tarv, dayfirst=True, errors="coerce")
                if pd.notna(fd) and pd.notna(ft):
                    _add_metric(IND_TARV_LT_DIAG, pais_row, mes_rep, depto_row, sitio_row, checks_add=1)
                    if ft < fd:
                        _add_metric(IND_TARV_LT_DIAG, pais_row, mes_rep, depto_row, sitio_row, errors_add=1)
                        errores_fecha_tarv.append({
                            "Pa√≠s": pais_row, "Departamento": depto_row, "Sitio": sitio_row, "Mes de reporte": mes_rep,
                            "Archivo": nombre_archivo, "Resultado": "Positivo" if resultado == "positivo" else "",
                            "Fecha diagn√≥stico": fd.date(), "Fecha inicio TARV": ft.date(),
                            "Fila Excel": int(fila_base_hts + i), "Columna Excel": col_tarv
                        })
            except Exception:
                pass

        # Formato de Fecha Diagn√≥stico (dd/mm/YYYY si trae '/')
        try:
            fecha_texto = str(fecha_diag).strip()
            if fecha_texto and "/" in fecha_texto:
                _add_metric(IND_DIAG_BAD_FMT, pais_row, mes_rep, depto_row, sitio_row, checks_add=1)
                partes = fecha_texto.split("/")
                if len(partes) == 3:
                    dia, mes_, anio = partes
                    if int(mes_) > 12: raise ValueError
                    datetime.strptime(fecha_texto, "%d/%m/%Y")
        except Exception:
            _add_metric(IND_DIAG_BAD_FMT, pais_row, mes_rep, depto_row, sitio_row, errors_add=1)
            errores_formato_fecha_diag.append({
                "Pa√≠s": pais_row, "Departamento": depto_row, "Sitio": sitio_row, "Mes de reporte": mes_rep,
                "Archivo": nombre_archivo,
                "Fecha del diagn√≥stico de la prueba": fecha_diag,
                "Fila Excel": int(fila_base_hts + i), "Columna Excel": col_diag
            })

    # ===========================
    # NUEVO: Duplicados de ID (N√∫mero de expediente)
    # ===========================
    col_id = (_first_col(df_data, "id", "expediente") or
              _first_col(df_data, "numero", "expediente") or
              _first_col(df_data, "n√∫mero", "expediente") or
              _first_col(df_data, "id"))
    if col_id:
        try:
            col_id_idx = list(df_data.columns).index(col_id)
        except ValueError:
            col_id_idx = None

        ids_raw = df_data[col_id].astype(str).str.strip()
        mask_non_empty = ids_raw.replace({"nan": "", "NaN": ""}).astype(bool)
        vc = ids_raw[mask_non_empty].value_counts()
        duplicados = vc[vc > 1]

        checks = int(mask_non_empty.sum())
        errs = int((duplicados - 1).sum()) if not duplicados.empty else 0
        _add_metric(IND_ID_DUPLICADO, pais_inferido, month_label_from_value(mes_inferido), checks_add=checks, errors_add=errs)

        if not duplicados.empty:
            for id_val, count in duplicados.items():
                idxs = df_data.index[ids_raw == id_val].tolist()
                r0 = df_data.loc[idxs[0]]

                pais_row  = str(_coerce_scalar(r0.get(col_pais)))  if col_pais  else pais_inferido
                depto_row = str(_coerce_scalar(r0.get(col_depto))) if col_depto else ""
                sitio_row = str(_coerce_scalar(r0.get(col_sitio)))  if col_sitio  else ""
                mes_rep   = month_label_from_value(_coerce_scalar(r0.get(col_diag))) or month_label_from_value(mes_inferido)

                pais_row  = pais_row.strip() or pais_inferido
                depto_row = depto_row.strip()
                sitio_row = sitio_row.strip()
                mes_rep   = mes_rep.strip() or month_label_from_value(mes_inferido)

                register_dim(pais_row, depto_row, sitio_row)

                filas_excel = [int(idx_hts + 3 + i) for i in idxs]  # misma base que HTS
                col_letter = get_column_letter(col_id_idx + 1) if col_id_idx is not None else col_id

                _add_metric(IND_ID_DUPLICADO, pais_row, mes_rep, depto_row, sitio_row, errors_add=(int(count) - 1))

                errores_iddup.append({
                    "Pa√≠s": pais_row,
                    "Departamento": depto_row,
                    "Sitio": sitio_row,
                    "Mes de reporte": mes_rep,
                    "Archivo": nombre_archivo,
                    "ID expediente": str(id_val),
                    "Ocurrencias": int(count),
                    "Filas Excel": ", ".join(map(str, filas_excel)),
                    "Columna Excel": col_letter,
                })

# ====== TX_CURR vs Dispensaci√≥n_TARV ======
def procesar_tx_curr_cuadros(
    xl: pd.ExcelFile, pais_inferido: str, mes_inferido: str,
    nombre_archivo: str, errores_currq
):
    sheet_name = "TX_CURR"
    if sheet_name not in xl.sheet_names: return
    df_raw = xl.parse(sheet_name, header=None)
    nrows, ncols = df_raw.shape

    def _find_label_positions(alternatives: List[List[str]]) -> List[Tuple[int,int]]:
        pos = []
        for r in range(nrows):
            for c in range(ncols):
                s = _norm(df_raw.iat[r, c])
                if not s: continue
                for toks in alternatives:
                    if all(tok in s for tok in toks):
                        pos.append((r, c)); break
        return pos

    pos_tx = _find_label_positions([["tx", "curr"]])
    pos_et = _find_label_positions([
        ["dispens", "tar"],
        ["dispensacion", "tar"],
        ["dispensaci√≥n", "tar"],
        ["entrega", "tar"],
        ["entrega", "tavr"],
    ])
    if not pos_tx or not pos_et:
        return

    fila_tx = min(pos_tx)[0]
    fila_et = min(pos_et)[0]

    def _find_header_after(start_row: int) -> Optional[int]:
        for r in range(start_row, min(start_row + 50, nrows)):
            row_vals = df_raw.iloc[r].tolist()
            if any("sexo" in _norm(x) for x in row_vals):
                cols = [str(x) for x in row_vals]
                cols_norm = [_norm(x) for x in cols]
                try:
                    col_sexo = next(i for i, cn in enumerate(cols_norm) if "sexo" in cn)
                except StopIteration:
                    continue
                edad_ok = any(
                    ("ano" in _norm(cols[j])) or ("a√±o" in _norm(cols[j])) or re.search(r"\b65\b", _norm(cols[j])) or
                    ("+" in _norm(cols[j])) or ("mas" in _norm(cols[j]) and "65" in _norm(cols[j]))
                    for j in range(col_sexo + 1, ncols)
                )
                if edad_ok:
                    return r
        return None

    hdr_tx = _find_header_after(fila_tx)
    hdr_et = _find_header_after(fila_et)
    if hdr_tx is None or hdr_et is None: return

    def _extract_table_totals(header_row: int, stop_row: Optional[int]):
        cols = df_raw.iloc[header_row].fillna("").astype(str).tolist()
        cols_norm = [_norm(x) for x in cols]
        try:
            col_sexo = next(i for i, cn in enumerate(cols_norm) if "sexo" in cn)
        except StopIteration:
            return {}, {}, None

        edad_idx, edad_key, edad_map = [], [], {}
        for j in range(col_sexo + 1, ncols):
            lab  = cols[j]; labn = _norm(lab)
            if ("ano" in labn) or ("a√±o" in labn) or re.search(r"\b65\b", labn) or ("+" in labn) or ("mas" in labn and "65" in labn):
                k = labn
                edad_idx.append(j); edad_key.append(k); edad_map[k] = str(lab)

        if not edad_idx:
            return {}, {}, col_sexo

        totals: Dict[Tuple[str,str], int] = {}
        r = header_row + 1
        while r < nrows:
            if stop_row is not None and r >= stop_row: break
            rown = [_norm(x) for x in df_raw.iloc[r].tolist()]
            if any("sexo" in x for x in rown): break
            sx_raw = df_raw.iat[r, col_sexo]
            sx = _normalize_sexo(sx_raw)
            if sx in ["Masculino", "Femenino"]:
                for c_idx, ekey in zip(edad_idx, edad_key):
                    v = pd.to_numeric(df_raw.iat[r, c_idx], errors="coerce")
                    if pd.notna(v):
                        v = int(round(float(v)))
                        key = (sx, ekey)
                        totals[key] = totals.get(key, 0) + v
            r += 1

        return totals, edad_map, col_sexo

    if hdr_tx < hdr_et:
        totals_tx, edades_tx, _ = _extract_table_totals(hdr_tx, hdr_et)
        totals_et, edades_et, _ = _extract_table_totals(hdr_et, None)
    else:
        totals_et, edades_et, _ = _extract_table_totals(hdr_et, hdr_tx)
        totals_tx, edades_tx, _ = _extract_table_totals(hdr_tx, None)

    cols_hdr = df_raw.iloc[hdr_tx].fillna("").astype(str).tolist()
    cols_hdrn = [_norm(x) for x in cols_hdr]

    def _find_col_idx(cols_norm, *patrones):
        for i, cn in enumerate(cols_norm):
            if all(p in cn for p in patrones):
                return i
        return None

    col_pais_i   = _find_col_idx(cols_hdrn, "pais")
    col_depto_i  = (_find_col_idx(cols_hdrn, "departamento") or
                    _find_col_idx(cols_hdrn, "depto") or
                    _find_col_idx(cols_hdrn, "provincia"))
    col_sitio_i  = (_find_col_idx(cols_hdrn, "servicio") or
                    _find_col_idx(cols_hdrn, "salud") or
                    _find_col_idx(cols_hdrn, "sitio") or
                    _find_col_idx(cols_hdrn, "clinica"))
    col_mesrep_i = (_find_col_idx(cols_hdrn, "fecha") if _find_col_idx(cols_hdrn, "reporte") is not None else None)
    if col_mesrep_i is None:
        col_mesrep_i = _find_col_idx(cols_hdrn, "mes")

    def _ctx_from_rowvals(row_vals):
        def _val(idx, fallback):
            try:
                v = row_vals[idx] if idx is not None else fallback
            except Exception:
                v = fallback
            v = str(v).strip()
            return v if v else fallback
        p = _val(col_pais_i, pais_inferido)
        d = _val(col_depto_i, "")
        s = _val(col_sitio_i, "")
        raw_mes = row_vals[col_mesrep_i] if col_mesrep_i is not None else None
        m = month_label_from_value(raw_mes) or month_label_from_value(mes_inferido)
        return p, d, s, m

    fila_ctx_vals = df_raw.iloc[hdr_tx + 1].fillna("").astype(str).tolist() if (hdr_tx + 1) < nrows else []
    pais_row, depto_row, sitio_row, mes_rep = _ctx_from_rowvals(fila_ctx_vals)
    register_dim(pais_row, depto_row, sitio_row)

    all_keys = set(totals_tx.keys()) | set(totals_et.keys())
    for (sexo, edad_key) in sorted(all_keys):
        v_tx = int(totals_tx.get((sexo, edad_key), 0))
        v_et = int(totals_et.get((sexo, edad_key), 0))
        etiqueta_edad = edades_tx.get(edad_key) or edades_et.get(edad_key) or edad_key

        _add_metric(IND_CURR_Q1Q2_DIFF, pais_row, mes_rep, depto_row, sitio_row, checks_add=1)
        if v_tx != v_et:
            _add_metric(IND_CURR_Q1Q2_DIFF, pais_row, mes_rep, depto_row, sitio_row, errors_add=1)
            errores_currq.append({
                "Pa√≠s": pais_row,
                "Departamento": depto_row,
                "Sitio": sitio_row,
                "Mes de reporte": mes_rep,
                "Archivo": nombre_archivo,
                "Sexo": sexo,
                "Rango de edad": etiqueta_edad,
                "TX_CURR": v_tx,
                "Dispensaci√≥n_TARV": v_et,
                "Diferencia (TX_CURR - Disp_TARV)": v_tx - v_et,
                "Disp_TARV > TX_CURR": "S√≠" if v_et > v_tx else "No",
            })

# ============================
# --------- PROCESO ----------
# ============================
if procesar:
    if not subida_multiple:
        st.warning("Primero carga archivos .xlsx o un .zip.")
        st.stop()

    entradas = []
    for up in subida_multiple:
        nombre = up.name; data = up.read()
        if nombre.lower().endswith(".zip"):
            with zipfile.ZipFile(io.BytesIO(data)) as zf:
                for info in zf.infolist():
                    if info.is_dir(): continue
                    if info.filename.lower().endswith(".xlsx") and not os.path.basename(info.filename).startswith("~$"):
                        entradas.append((os.path.basename(info.filename), zf.read(info.filename), info.filename))
        else:
            if nombre.lower().endswith(".xlsx") and not os.path.basename(nombre).startswith("~$"):
                entradas.append((os.path.basename(nombre), data, nombre))

    if not entradas:
        st.error("No se encontraron archivos .xlsx v√°lidos.")
        st.stop()

    errores_numerador = []
    errores_txpvls = []
    errores_cd4 = []
    errores_fecha_tarv = []
    errores_formato_fecha_diag = []
    errores_currq = []   # TX_CURR ‚â† Dispensaci√≥n_TARV
    errores_iddup = []   # NUEVO: IDs duplicados HTS_TST

    # Reiniciar m√©tricas y cat√°logo
    st.session_state.metrics_global = defaultdict(lambda: {"errors": 0, "checks": 0})
    st.session_state.metrics_by_pds = defaultdict(lambda: {"errors": 0, "checks": 0})
    st.session_state.dim_locs = set()

    progreso = st.progress(0.0, text="Procesando archivos‚Ä¶"); total = len(entradas)
    for idx, (nombre_archivo, data_bytes, ruta_rel) in enumerate(entradas, start=1):
        try:
            pais_inf, mes_inf = inferir_pais_mes(ruta_rel.replace("\\", "/"), default_pais, default_mes)
            register_dim(pais_inf, "", "")
            xl = leer_excel_desde_bytes(nombre_archivo, data_bytes)
            procesar_tx_pvls_y_curr(xl, pais_inf, mes_inf, nombre_archivo, errores_numerador, errores_txpvls)
            procesar_hts_tst(xl, pais_inf, mes_inf, nombre_archivo,
                             errores_cd4, errores_fecha_tarv, errores_formato_fecha_diag, errores_iddup)
            procesar_tx_curr_cuadros(xl, pais_inf, mes_inf, nombre_archivo, errores_currq)
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Error procesando {nombre_archivo}: {e}")
        progreso.progress(idx/total, text=f"Procesando {idx} de {total}‚Ä¶")

    # Guardar DataFrames en sesi√≥n
    st.session_state.df_num   = pd.DataFrame(errores_numerador)
    st.session_state.df_txpv  = pd.DataFrame(errores_txpvls)
    st.session_state.df_cd4   = pd.DataFrame(errores_cd4)
    st.session_state.df_tarv  = pd.DataFrame(errores_fecha_tarv)
    st.session_state.df_fdiag = pd.DataFrame(errores_formato_fecha_diag)
    st.session_state.df_currq = pd.DataFrame(errores_currq)
    st.session_state.df_iddup = pd.DataFrame(errores_iddup)
    st.session_state.processed = True

    # Construir cat√°logo maestro de ubicaciones para segmentadores
    if st.session_state.dim_locs:
        st.session_state.dim_df = pd.DataFrame(
            sorted(list(st.session_state.dim_locs)),
            columns=["Pa√≠s", "Departamento", "Sitio"]
        )
    else:
        st.session_state.dim_df = pd.DataFrame(columns=["Pa√≠s", "Departamento", "Sitio"])

    st.success("Procesamiento completado. Ahora puedes filtrar al instante ‚úÖ")

# ============================
# ------- INTERFAZ (LIVE) ----
# ============================
if not st.session_state.processed:
    st.info("Carga tus archivos y pulsa **Procesar**.")
    st.stop()

# Asegurar columnas base en DF de errores
for dfname in ["df_num","df_txpv","df_cd4","df_tarv","df_fdiag","df_currq","df_iddup"]:
    df = st.session_state[dfname]
    if not df.empty:
        for col in ["Pa√≠s","Departamento","Sitio","Mes de reporte"]:
            if col not in df.columns:
                st.session_state[dfname][col] = ""

# ===== Helpers de segmentadores =====
def ensure_in_options(value: str, options: List[str]) -> str:
    return value if value in options else "Todos"

# ===== Limpieza y construcci√≥n de SEGMENTADORES =====
_VALID_TXT_RE = re.compile(r"^[A-Za-z√Å√â√ç√ì√ö√ú√ë√°√©√≠√≥√∫√º√±'‚Äô -]{2,}$")
_MESES_LOWER = {m.lower() for m in MESES}

def _es_texto_lugar_valido(val: str) -> bool:
    if val is None:
        return False
    s = str(val).strip()
    if not s:
        return False
    sl = s.lower()
    if any(ch.isdigit() for ch in sl):
        return False
    toks = re.split(r"[\s_\-./]+", sl)
    if any(t in _MESES_LOWER for t in toks) or sl in _MESES_LOWER:
        return False
    return bool(_VALID_TXT_RE.match(s))

def _es_pais_valido(val: str) -> bool:
    return _es_texto_lugar_valido(val)

dim_df = st.session_state.dim_df.copy()
mask_clean = dim_df["Pa√≠s"].map(_es_pais_valido)
dim_df_clean = dim_df[mask_clean].copy()
for col in ["Pa√≠s", "Departamento", "Sitio"]:
    if col in dim_df_clean.columns:
        dim_df_clean[col] = dim_df_clean[col].map(_canon_txt)
dim_df_clean = dim_df_clean.drop_duplicates(subset=["Pa√≠s", "Departamento", "Sitio"]).reset_index(drop=True)

# ===== 1) SEGMENTADORES (cascada real y LIMPIOS) =====
with card("Segmentadores", "üéõÔ∏è"):
    paises_all = sorted([
        p for p in dim_df_clean["Pa√≠s"].dropna().unique().tolist()
        if _es_pais_valido(p)
    ])
    paises = ["Todos"] + paises_all
    st.session_state.sel_pais = ensure_in_options(st.session_state.sel_pais, paises)
    sel_pais = st.selectbox("Pa√≠s", paises, index=paises.index(st.session_state.sel_pais), key="sel_pais")

    if sel_pais != "Todos":
        departs_all = sorted([
            d for d in dim_df_clean.loc[dim_df_clean["Pa√≠s"] == sel_pais, "Departamento"]
            .dropna().unique().tolist()
            if d and _es_texto_lugar_valido(d)
        ])
    else:
        departs_all = sorted([
            d for d in dim_df_clean["Departamento"].dropna().unique().tolist()
            if d and _es_texto_lugar_valido(d)
        ])
    departs = ["Todos"] + departs_all
    st.session_state.sel_depto = ensure_in_options(st.session_state.sel_depto, departs)
    sel_depto = st.selectbox("Departamento", departs, index=departs.index(st.session_state.sel_depto), key="sel_depto")

    mask = pd.Series([True] * len(dim_df_clean))
    if sel_pais  != "Todos": mask &= (dim_df_clean["Pa√≠s"] == sel_pais)
    if sel_depto != "Todos": mask &= (dim_df_clean["Departamento"] == sel_depto)
    sitios_all = sorted([
        s for s in dim_df_clean.loc[mask, "Sitio"].dropna().unique().tolist()
        if s and _es_texto_lugar_valido(s)
    ])
    if sel_pais == "Todos" and sel_depto == "Todos" and not sitios_all:
        sitios_all = sorted([
            s for s in dim_df_clean["Sitio"].dropna().unique().tolist()
            if s and _es_texto_lugar_valido(s)
        ])
    sitios = ["Todos"] + sitios_all
    st.session_state.sel_sitio = ensure_in_options(st.session_state.sel_sitio, sitios)
    sel_sitio = st.selectbox("Sitio", sitios, index=sitios.index(st.session_state.sel_sitio), key="sel_sitio")

# Filtro aplicado a cada DF de errores
def _aplicar_filtro(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty: return df
    m = pd.Series([True] * len(df))
    if st.session_state.sel_pais  != "Todos": m &= (df["Pa√≠s"] == st.session_state.sel_pais)
    if st.session_state.sel_depto != "Todos": m &= (df["Departamento"] == st.session_state.sel_depto)
    if st.session_state.sel_sitio != "Todos": m &= (df["Sitio"] == st.session_state.sel_sitio)
    return df[m].copy()

df_num_f   = _aplicar_filtro(st.session_state.df_num)
df_txpv_f  = _aplicar_filtro(st.session_state.df_txpv)
df_cd4_f   = _aplicar_filtro(st.session_state.df_cd4)
df_tarv_f  = _aplicar_filtro(st.session_state.df_tarv)
df_fdiag_f = _aplicar_filtro(st.session_state.df_fdiag)
df_currq_f = _aplicar_filtro(st.session_state.df_currq)
df_iddup_f = _aplicar_filtro(st.session_state.df_iddup)  # NUEVO

# M√©tricas (adaptadas a la selecci√≥n)
def _build_metrics_df_from_selection(sel_pais, sel_depto, sel_sitio):
    agg = defaultdict(lambda: {"errors": 0, "checks": 0})
    for (pais, depto, sitio, mes_rep, ind), v in st.session_state.metrics_by_pds.items():
        if (sel_pais == "Todos" or pais == sel_pais) and \
           (sel_depto == "Todos" or depto == sel_depto) and \
           (sel_sitio == "Todos" or sitio == sel_sitio):
            agg[ind]["errors"] += v["errors"]; agg[ind]["checks"] += v["checks"]

    df_global = (pd.DataFrame([
        {"Indicador": DISPLAY_NAMES.get(k, k), "Errores": v["errors"], "Chequeos": v["checks"], "% Error": _pct(v["errors"], v["checks"])}
        for k, v in agg.items()
    ]).sort_values("% Error", ascending=False)
    if agg else pd.DataFrame(columns=["Indicador","Errores","Chequeos","% Error"]))

    rows = []
    for (pais, depto, sitio, mes_rep, ind), v in st.session_state.metrics_by_pds.items():
        if (sel_pais == "Todos" or pais == sel_pais) and \
           (sel_depto == "Todos" or depto == sel_depto) and \
           (sel_sitio == "Todos" or sitio == sel_sitio):
            rows.append({
                "Pa√≠s": pais, "Departamento": depto, "Sitio": sitio, "Mes de reporte": mes_rep,
                "Indicador": DISPLAY_NAMES.get(ind, ind), "Errores": v["errors"], "Chequeos": v["checks"],
                "% Error": _pct(v["errors"], v["checks"])
            })
    df_group = pd.DataFrame(rows)
    if not df_group.empty:
        df_group = df_group[["Pa√≠s","Departamento","Sitio","Mes de reporte","Indicador","Errores","Chequeos","% Error"]]
        df_group = df_group.sort_values(["Pa√≠s","Departamento","Sitio","Indicador"])
    else:
        df_group = pd.DataFrame(columns=["Pa√≠s","Departamento","Sitio","Mes de reporte","Indicador","Errores","Chequeos","% Error"])
    return df_global, df_group

df_metricas_global_sel, df_metricas_por_mes_sel = _build_metrics_df_from_selection(
    st.session_state.sel_pais, st.session_state.sel_depto, st.session_state.sel_sitio
)

# ===== 2) RESUMEN (usa DF FILTRADOS) =====
with card("Resumen (conteo de filas de error)", "üìå", badge="Aplica filtros"):
    c1, c2, c3, c4, c5, c6, c7 = st.columns(7)
    c1.metric("Numerador > Denominador", len(df_num_f))
    c2.metric("Denominador > TX_CURR", len(df_txpv_f))
    c3.metric("CD4 vac√≠o positivo", len(df_cd4_f))
    c4.metric("TARV < Diagn√≥stico", len(df_tarv_f))
    c5.metric("Fecha diag. mal formateada", len(df_fdiag_f))
    c6.metric("TX_CURR ‚â† Dispensaci√≥n_TARV", len(df_currq_f))
    c7.metric("ID (expediente) duplicado", len(df_iddup_f))

# ===== 3) INDICADORES ‚Äì % DE ERROR =====
with card("Indicadores ‚Äì % de error (selecci√≥n)", "üßÆ"):
    cards = [
        IND_NUM_GT_DEN, IND_DEN_GT_CURR, IND_CD4_MISSING,
        IND_TARV_LT_DIAG, IND_DIAG_BAD_FMT, IND_CURR_Q1Q2_DIFF,
        IND_ID_DUPLICADO
    ]
    cols = st.columns(len(cards))
    sel_map = {row["Indicador"]: row for _, row in df_metricas_global_sel.iterrows()} if not df_metricas_global_sel.empty else {}
    for col, key in zip(cols, cards):
        name = DISPLAY_NAMES[key]
        v = sel_map.get(name, {"Errores":0, "Chequeos":0, "% Error":0})
        col.metric(label=name, value=f"{v.get('% Error',0)}%", delta=f"{v.get('Errores',0)} / {v.get('Chequeos',0)} err/cheq")

# ===== 4) DETALLE POR INDICADOR =====
with card("Detalle por indicador", "üîé"):
    tabs = st.tabs([
        "Numerador > Denominador",
        "Denominador > TX_CURR",
        "CD4 vac√≠o positivo",
        "Fecha TARV < Diagn√≥stico",
        "Formato fecha diagn√≥stico",
        "TX_CURR ‚â† Dispensaci√≥n_TARV",
        "ID (expediente) duplicado",
    ])
    with tabs[0]: show_df_or_note(df_num_f,   "‚Äî Sin diferencias de Numerador > Denominador ‚Äî", height=320)
    with tabs[1]: show_df_or_note(df_txpv_f,  "‚Äî Sin casos Denominador > TX_CURR ‚Äî", height=320)
    with tabs[2]: show_df_or_note(df_cd4_f,   "‚Äî Sin positivos con CD4 vac√≠o ‚Äî", height=320)
    with tabs[3]: show_df_or_note(df_tarv_f,  "‚Äî Sin casos TARV < Diagn√≥stico ‚Äî", height=320)
    with tabs[4]: show_df_or_note(df_fdiag_f, "‚Äî Sin problemas de formato de fecha ‚Äî", height=320)
    with tabs[5]: show_df_or_note(df_currq_f, "‚Äî TX_CURR = Dispensaci√≥n_TARV en la selecci√≥n ‚Äî", height=320)
    with tabs[6]: show_df_or_note(df_iddup_f, "‚Äî Sin IDs duplicados en la selecci√≥n ‚Äî", height=320)

# ===== 5) M√âTRICAS =====
with card("M√©tricas de calidad (adaptadas al filtro)", "üìà"):
    gc1, gc2 = st.columns([1.2, 2])
    with gc1:
        st.markdown("**M√©tricas ‚Äì Selecci√≥n actual**")
        show_df_or_note(df_metricas_global_sel, "‚Äî Sin m√©tricas para la selecci√≥n ‚Äî", height=260)
    with gc2:
        st.markdown("**Desglose por Mes ‚Äì Selecci√≥n**")
        show_df_or_note(df_metricas_por_mes_sel, "‚Äî Sin desglose para la selecci√≥n ‚Äî", height=260)

# ============================
# ---------- DESCARGA --------
# ============================
def exportar_excel_resultados(errores_dict, df_metricas_global: pd.DataFrame, df_metricas_group: pd.DataFrame) -> bytes:
    config_resaltado = {
        "Numerador > Denominador": "Numerador",
        "Denominador > TX_CURR": "Denominador (PVLS)",
        "CD4 vac√≠o positivo": "CD4 Basal",
        "Fecha TARV < Diagn√≥stico": "Fecha inicio TARV",
        "Formato fecha diagn√≥stico": "Fecha del diagn√≥stico de la prueba",
        "TX_CURR ‚â† Dispensaci√≥n_TARV": "Diferencia (TX_CURR - Disp_TARV)",
        "ID (expediente) duplicado": "ID expediente",
    }
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        used = set()
        resumen = pd.DataFrame({
            "Tipo de Error": list(errores_dict.keys()),
            "Total": [len(df) for df in errores_dict.values()]
        })
        resumen.to_excel(writer, index=False, sheet_name=_safe_sheet_name("Resumen", used))
        for nombre, df in errores_dict.items():
            if df is not None and not df.empty:
                df.to_excel(writer, index=False, sheet_name=_safe_sheet_name(nombre, used))
        if df_metricas_global is not None and not df_metricas_global.empty:
            df_metricas_global.to_excel(writer, index=False, sheet_name=_safe_sheet_name("Metricas Globales Seleccion", used))
        if df_metricas_group is not None and not df_metricas_group.empty:
            df_metricas_group.to_excel(writer, index=False, sheet_name=_safe_sheet_name("Metricas por Mes", used))

    buffer.seek(0); wb = load_workbook(buffer)
    rojo = PatternFill(start_color="FF0000", end_color="FF0000", fill_type="solid")

    for nombre, df in errores_dict.items():
        if df is None or df.empty: continue
        target = None
        for ws in wb.worksheets:
            if ws.title.lower().startswith(_safe_sheet_name(nombre, set()).lower()[:5]):
                target = ws.title; break
        if not target: continue
        ws = wb[target]
        campo_rojo = config_resaltado.get(nombre)
        if campo_rojo and campo_rojo in df.columns:
            col_idx = list(df.columns).index(campo_rojo) + 1
            for row in range(2, ws.max_row + 1):
                ws.cell(row=row, column=col_idx).fill = rojo
        ws.auto_filter.ref = ws.dimensions

    out = io.BytesIO(); wb.save(out); out.seek(0)
    return out.getvalue()

full_dict = {
    "Numerador > Denominador": st.session_state.df_num,
    "Denominador > TX_CURR": st.session_state.df_txpv,
    "CD4 vac√≠o positivo": st.session_state.df_cd4,
    "Fecha TARV < Diagn√≥stico": st.session_state.df_tarv,
    "Formato fecha diagn√≥stico": st.session_state.df_fdiag,
    "TX_CURR ‚â† Dispensaci√≥n_TARV": st.session_state.df_currq,
    "ID (expediente) duplicado": st.session_state.df_iddup,
}

rows_metrics_global = [
    {"Indicador": DISPLAY_NAMES[k], "Errores": v["errors"], "Chequeos": v["checks"], "% Error": _pct(v["errors"], v["checks"])}
    for k, v in st.session_state.metrics_global.items()
]
df_metricas_global_all = (
    pd.DataFrame(rows_metrics_global).sort_values("% Error", ascending=False)
    if rows_metrics_global else pd.DataFrame(columns=["Indicador","Errores","Chequeos","% Error"])
)

rows_all = []
for (pais, depto, sitio, mes_rep, ind), v in st.session_state.metrics_by_pds.items():
    rows_all.append({
        "Pa√≠s": pais, "Departamento": depto, "Sitio": sitio, "Mes de reporte": mes_rep,
        "Indicador": DISPLAY_NAMES[ind], "Errores": v["errors"], "Chequeos": v["checks"],
        "% Error": _pct(v["errors"], v["checks"])
    })
df_metricas_por_mes_all = pd.DataFrame(rows_all)
if not df_metricas_por_mes_all.empty:
    df_metricas_por_mes_all = df_metricas_por_mes_all[["Pa√≠s","Departamento","Sitio","Mes de reporte","Indicador","Errores","Chequeos","% Error"]]
    df_metricas_por_mes_all = df_metricas_por_mes_all.sort_values(["Pa√≠s","Departamento","Sitio","Indicador"])

bytes_excel_full = exportar_excel_resultados(full_dict, df_metricas_global_all, df_metricas_por_mes_all)

filt_dict = {
    "Numerador > Denominador": df_num_f,
    "Denominador > TX_CURR": df_txpv_f,
    "CD4 vac√≠o positivo": df_cd4_f,
    "Fecha TARV < Diagn√≥stico": df_tarv_f,
    "Formato fecha diagn√≥stico": df_fdiag_f,
    "TX_CURR ‚â† Dispensaci√≥n_TARV": df_currq_f,
    "ID (expediente) duplicado": df_iddup_f,
}
bytes_excel_filt = exportar_excel_resultados(filt_dict, df_metricas_global_sel, df_metricas_por_mes_sel)

with card("Descargas", "‚¨áÔ∏è"):
    fecha_str = datetime.now().strftime("%Y%m%d_%H%M")
    cdl1, cdl2 = st.columns(2)
    with cdl1:
        st.download_button("Descargar Excel (COMPLETO)", data=bytes_excel_full,
            file_name=f"VALIDACIONES_MAESTRO_VIH_COMPLETO_{fecha_str}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)
    with cdl2:
        st.download_button("Descargar Excel (FILTRADO)", data=bytes_excel_filt,
            file_name=f"VALIDACIONES_MAESTRO_VIH_FILTRADO_{fecha_str}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)
